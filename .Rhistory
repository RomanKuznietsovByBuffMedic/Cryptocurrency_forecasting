rm(list = setdiff(ls(), lsf.str()))
df <- 10
pars <- list(
left_X  = -3,
right_X = 3,
dist = "t",
dist_pars = list(df = df)
)
title <- glue("розподілу Стьюдента з $df = {df}$")
generate_data(pars, for_plot = F) %>%
my_print_tibble()
generate_data(pars) %>%
my_plot("generic",
data = .,
title = title)
generate_data(pars, dfr = F, for_plot = F) %>%
my_print_tibble(dfr = F)
generate_data(pars, dfr = F) %>%
my_plot("generic",
data = .,
title = title,
dfr = F)
alpha <- 0.05
z_alpha <- qt(alpha, df, lower.tail = F)
rm(list = setdiff(ls(), lsf.str()))
df <- 10
pars <- list(
left_X  = 0,
right_X = 10,
dist = "chisq",
dist_pars = list(df = df)
)
title <- glue("розподілу Пірсона з $df = {df}$")
generate_data(pars) %>%
my_plot("generic",
data = .,
title = title)
round(df*2.5)
df <- 10
pars <- list(
left_X  = 0,
right_X = round(df*2.5),
dist = "chisq",
dist_pars = list(df = df)
)
title <- glue("розподілу Пірсона з $df = {df}$")
generate_data(pars) %>%
my_plot("generic",
data = .,
title = title)
# check your number of logic cores
install_libs <- function(num_cores = 8)
{
# install "pacman" for install and load libs
# pacman::p_install(libs), pacman::p_load(libs)
if (!require("pacman"))
install.packages("pacman", Ncpus = num_cores)
# install neded libs
pacman::p_load(
package = c(
# read EXel files
# "readxl",
# read_EXcel(file)
# rewrite to "pro" data.frame
"tibble",
# as_tible(data)
# tibble(write a data)
# work with data
# "janitor",
# clean_names(df)
# "hablar",
# retype(df)
# "varhandle",
# unfactor(df)
"dplyr",
# data manipulation like mutate()
# purrr,
# map(), etc.; immediately use parallelization
"tidyr",
# create tidy (nice) data like pivor_longer
# nice number format FOR TIBBLE
# after run, run this with each upd, upgrd, reboot
# sudo apt update && sudo apt upgrade && sudo rebot
# sudo apt install libcurl4-openssl-dev
# sudo apt install libv8-dev
# sudo apt install libxml2-dev
"gt",
# my_tibble |> gt() |> fmt_scientific()
# for get train/test set
# "caret",
# sample <- createDataPartition(as.factor(df[[y_name]]), p = 0.8, list = F)
# plots
"ggplot2",
# pROC,
# ggroc(roc(data[[y_name]], predict(model, data)))
# easy print string
"glue",
# glue("Hello {word}")
# add LaTeX
"latex2exp",
# TeX("\\textbf{Euler's identity} is $e^{i\\pi} + 1 = 0$.")
# fast code
"compiler",
# func <- cmpfun(func); `enableJIT(3)`
# "furrr",
# future_map(), etc.; parallel with `plan(multisession)`
# parallel,
# mclapply(), etc.
# RMarkdown
# "rmarkdown",
# "knitr",
# kable(data)
# "tinytEX"
),
character.only = T,
# let's do it faster
Ncpus = num_cores
)
}
install.packages("officer")
library(officer)
install.packages("officer")
install.packages("officer")
install.packages("docxtractr")   # легкий пакет, без textshaping
library(docxtractr)
getwd()
getwd()
# ------------------------------------------------------------
# connect libs
# check your number of logic cores
install_libs <- function(num_cores = 8)
{
# install "pacman" for install and load libs
# pacman::p_install(libs), pacman::p_load(libs)
if (!require("pacman"))
install.packages("pacman", Ncpus = num_cores)
# install neded libs
pacman::p_load(
package = c(
# read Word files
"docxtractr",
# doc <- read_docx("file_name.docx")
# docx_extract_tbl(doc, 1)
# docx_extract_all_tbls(doc)
# read EXel files
# "readxl",
# read_EXcel(file)
# rewrite to "pro" data.frame
# "tibble",
# as_tible(data)
# tibble(write a data)
# work with data
# "janitor",
# clean_names(df)
# "hablar",
# retype(df)
# "varhandle",
# unfactor(df)
"dplyr",
# data manipulation like mutate()
# purrr,
# map(), etc.; immediately use parallelization
# "tidyr",
# create tidy (nice) data like pivor_longer
# nice number format FOR TIBBLE
# after run, run this with each upd, upgrd, reboot
# sudo apt update && sudo apt upgrade && sudo rebot
# sudo apt install libcurl4-openssl-dev
# sudo apt install libv8-dev
# sudo apt install libxml2-dev
"gt",
# my_tibble |> gt() |> fmt_scientific()
# for get train/test set
# "caret",
# sample <- createDataPartition(as.factor(df[[y_name]]), p = 0.8, list = F)
# plots
"ggplot2",
# pROC,
# ggroc(roc(data[[y_name]], predict(model, data)))
# easy print string
"glue",
# glue("Hello {word}")
# add LaTeX
"latex2exp"
# TeX("\\textbf{Euler's identity} is $e^{i\\pi} + 1 = 0$.")
# fast code
# "compiler"
# func <- cmpfun(func)
# https://www.r-statistics.com/2012/04/speed-up-your-r-code-using-a-just-in-time-jit-compiler/
# enableJIT(3)
# "furrr",
# future_map(), etc.; parallel with `plan(multisession)`
# parallel,
# mclapply(), etc.
# RMarkdown
# "rmarkdown",
# "knitr",
# kable(data)
# "tinytEX"
),
character.only = T,
# let's do it faster
Ncpus = num_cores
)
}
install_libs()
# so as not to interfere
rm(install_libs)
# ------------------------------------------------------------
# create helpful functions
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
file_name_with_path <- paste0(getwd(), file_name)
doc <- read_docx(file_name_with_path)   # це ФУНКЦІЯ пакета docxtractr
tables <- docx_extract_all_tbls(doc) # скільки є – дивимось довжину
tbl <- tables[[1]]                  # перша (єдина) таблиця
vec <- as.numeric(unlist(tbl))
}
read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
file_name_with_path <- paste0(getwd(), "/", file_name)
doc <- read_docx(file_name_with_path)   # це ФУНКЦІЯ пакета docxtractr
tables <- docx_extract_all_tbls(doc) # скільки є – дивимось довжину
tbl <- tables[[1]]                  # перша (єдина) таблиця
vec <- as.numeric(unlist(tbl))
}
read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
file_name_with_path <- paste0(getwd(), "/", file_name)
doc <- read_docx(file_name_with_path)   # це ФУНКЦІЯ пакета docxtractr
tables <- docx_extract_all_tbls(doc) # скільки є – дивимось довжину
tbl <- tables[[1]]                  # перша (єдина) таблиця
as.numeric(unlist(tbl))
}
read_table_from_docx("Розрахункове завдання 3.docx")
v <- read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
file_name_with_path <- paste0(getwd(), "/", file_name)
doc <- read_docx(file_name_with_path)   # це ФУНКЦІЯ пакета docxtractr
tbl <- docx_extract_tbl(doc, 1)
as.numeric(unlist(tbl))
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
file_name_with_path <- paste0(getwd(), "/", file_name)
doc <- read_docx(file_name_with_path)   # це ФУНКЦІЯ пакета docxtractr
tbl <- docx_extract_tbl(doc, 1, header = F)
as.numeric(unlist(tbl))
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
v
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
paste0(getwd(), "/", file_name) |>
read_docx() |>
docx_extract_tbl(1, header = F) |>
as.numeric(unlist(.))
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
paste0(getwd(), "/", file_name) |>
read_docx() |>
docx_extract_tbl(1, header = F) |>
unlist() |>
as.numeric()
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
v
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
paste0(getwd(), "/", file_name) |>
read_docx() |>
docx_extract_tbl(1, header = F) |>
unlist() #|>
# as.numeric()
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
# file_name.docx and this source mus tbe in the same folder
read_table_from_docx <- function(file_name)
{
paste0(getwd(), "/", file_name) |>
read_docx() |>
docx_extract_tbl(1, header = F) |>
unlist() |>
as.numeric()
}
v <- read_table_from_docx("Розрахункове завдання 3.docx")
v
# ------------------------------------------------------------
# connect libs
# check your number of logic cores
install_libs <- function(num_cores = 8)
{
# install "pacman" for install and load libs
# pacman::p_install(libs), pacman::p_load(libs)
if (!require("pacman"))
install.packages("pacman", Ncpus = num_cores)
# install neded libs
pacman::p_load(
package = c(
# read Word files
"docxtractr",
# doc <- read_docx("file_name.docx")
# docx_extract_tbl(doc, 1)
# docx_extract_all_tbls(doc)
# read EXel files
# "readxl",
# read_EXcel(file)
# rewrite to "pro" data.frame
# "tibble",
# as_tible(data)
# tibble(write a data)
# work with data
# "janitor",
# clean_names(df)
# "hablar",
# retype(df)
# "varhandle",
# unfactor(df)
# "dplyr",
# data manipulation like mutate()
# purrr,
# map(), etc.; immediately use parallelization
# "tidyr",
# create tidy (nice) data like pivor_longer
# nice number format FOR TIBBLE
# after run, run this with each upd, upgrd, reboot
# sudo apt update && sudo apt upgrade && sudo rebot
# sudo apt install libcurl4-openssl-dev
# sudo apt install libv8-dev
# sudo apt install libxml2-dev
# "gt",
# my_tibble |> gt() |> fmt_scientific()
# for get train/test set
# "caret",
# sample <- createDataPartition(as.factor(df[[y_name]]), p = 0.8, list = F)
# plots
"ggplot2",
# pROC,
# ggroc(roc(data[[y_name]], predict(model, data)))
# easy print string
"glue",
# glue("Hello {word}")
# add LaTeX
"latex2exp"
# TeX("\\textbf{Euler's identity} is $e^{i\\pi} + 1 = 0$.")
# fast code
# "compiler"
# func <- cmpfun(func)
# https://www.r-statistics.com/2012/04/speed-up-your-r-code-using-a-just-in-time-jit-compiler/
# enableJIT(3)
# "furrr",
# future_map(), etc.; parallel with `plan(multisession)`
# parallel,
# mclapply(), etc.
# RMarkdown
# "rmarkdown",
# "knitr",
# kable(data)
# "tinytEX"
),
character.only = T,
# let's do it faster
Ncpus = num_cores
)
}
install_libs()
# so as not to interfere
rm(install_libs)
# ------------------------------------------------------------
# create helpful functions
# file_name and this source must be in the same folder
read_table_from_docx <- function(file_name)
{
paste0(getwd(), "/", file_name) |>
read_docx() |>
docx_extract_tbl(1, header = F) |>
unlist() |>
as.numeric()
}
# approx number and convert in E format
my_approx <- function(number, digits = 2, format = "E")
formatC(number, digits, format = format)
v <- read_table_from_docx("Розрахункове завдання 3.docx")
v <- read_table_from_docx("Розрахункове завдання 3.docx")
mean_v <- mean(v)
# https://www.programmingr.com/statistics/how-to-calculate-mode-in-r/
get_mode <- function(x) {
keys <- unique(x)
keys[which.max(tabulate(match(x, keys)))]
}
mode_v <- get_mode(v)
table(v)
v |>
table()
v |>
table() |>
which.max()
v |>
table() |>
which.max() |>
names()
v |>
table() |>
which.max() |>
names() |>
as.numeric()
v |>
table() |>
which.max() |>
names() |>
as.numeric() -> mode_v
getwd()
getwd()
getwd()
library(readr)
BTCUSDT_Binance_futures_UM_hour <- read_delim("projobBabok/BTCUSDT_Binance_futures_UM_hour.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE,
skip = 2)
View(BTCUSDT_Binance_futures_UM_hour)
library(readr)
data <- read_delim("projobBabok/BTCUSDT_Binance_futures_UM_hour.csv",
delim = ";", escape_double = FALSE, trim_ws = TRUE,
skip = 2)
View(data)
getwd()
dirname(sys.frame(1)$ofile)
dirname()
sys.frame(1)
sys.frame()
sys.frame()$ofile
normalizePath(dirname(commandArgs(trailingOnly = FALSE)[[1]]))
data <- read_delim(
paste0(getwd(), "/", name),
delim = ";",
escape_double = F,
trim_ws = T,
skip = 2
)
library(readr)
name <- "BTCUSDT_Binance_futures_UM_hour.csv"
data <- read_delim(
paste0(getwd(), "/", name),
delim = ";",
escape_double = F,
trim_ws = T,
skip = 2
)
cumsum(1:10)
library(dplyr)
# Приклад даних: час вимірювань з розривом
df <- tibble::tibble(
Date = as.POSIXct(c(
"2024-06-01 00:00", "2024-06-01 01:00", "2024-06-01 02:00",
"2024-06-01 05:00", # розрив (3 години)
"2024-06-01 06:00", "2024-06-01 07:00"
))
)
View(df)
df %>%
arrange(Date) %>%
mutate(
time_diff = as.numeric(difftime(Date, lag(Date), units = "hours")),
group = cumsum(is.na(time_diff) | time_diff > 1)
) %>%
print
library(readr)
library(tidyr)
library(dplyr)
# read
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
name <- "BTCUSDT_Binance_futures_UM_hour.csv"
data <- read_delim(
name,
delim = ";",
escape_double = F,
trim_ws = T,
skip = 2
)
# clear data
data %>%
# Remove rows with any missing values
drop_na() %>%
# Create a day identifier
arrange(Date) %>%
mutate(
day = as.Date(Date)
) %>%
# Keep only days with 24 rows (full day)
group_by(day) %>%
filter(n() == 24) %>%
ungroup() %>%
mutate(
time_diff = as.numeric(difftime(Date, lag(Date), units = "hours")),
group = cumsum(is.na(time_diff) | time_diff > 1)
) %>%
group_by(group) -> test
result <- group_split(test)
View(test)
